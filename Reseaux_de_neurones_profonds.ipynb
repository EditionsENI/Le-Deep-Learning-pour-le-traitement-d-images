{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "isyvChpp3x1Z"
   },
   "source": [
    "# Classifier les fleurs d'iris selon leur espèce grâce à un réseau de neurones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cmSqc1mI3x1f"
   },
   "source": [
    "## Imports <a class=\"anchor\" id=\"imports\"></a>\n",
    "Nous commençons par importer les paquets nécessaires pour ce notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous chargeons également l'extension de TensorBoard pour les notebooks. \n",
    "Cette commande n'est pas nécessaire lorsque notre code Python n'est pas dans un notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rbIDLvJ23x1g"
   },
   "source": [
    "## Création du modèle\n",
    "\n",
    "Nous utilisons ici un modèle séquentiel avec 3 couches complètement connectées. \n",
    "- Les deux premières couches contiennent chacune 8 neurones, et ont une fonction d'activation sigmoide ;\n",
    "- La dernière couche contient 3 neurones, et a une fonction d'activation sigmoïde. Ainsi, la sortie de cette couche sera constituée de 3 nombres entre 0 et 1 et dont la somme vaut 1, qui pourront être interprétés comme des probabilités. \n",
    "\n",
    "Nous n'ajoutons pas d'extinction de neurones à ce réseau, car chaque couche ne contient que peu de neurones. Eventuellement, si nous voyons que le réseau est en situation de surapprentissage, nous pourrons ajouter une couche d'extinction de neurones, avec un taux d'extinction faible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(8, activation='relu', input_shape=(4,)))\n",
    "model.add(layers.Dense(8, activation='relu'))\n",
    "model.add(layers.Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement et séparation des données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifions la dimension de chacun de ces éléments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 4) (60, 4) (90,) (60,)\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train a 90 lignes et 4 colonnes : il contient donc 90 exemples, chacun avec 4 caractéristiques. \n",
    "\n",
    "X_test a 60 lignes et 4 colonnes : cet ensemble contient 60 exemples, chacun ayant lui aussi 4 caractéristiques. \n",
    "\n",
    "Les vecteurs y_train et y_test ont pour taille respective 90 et 60, ce qui est cohérent avec la taille des matrices X_train et X_test. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion des étiquettes en vecteurs au format un parmi n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cat = tf.keras.utils.to_categorical(y_train)\n",
    "y_test_cat = tf.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifions une nouvelle fois la dimension de ces éléments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 3) (60, 3)\n"
     ]
    }
   ],
   "source": [
    "print (y_train_cat.shape, y_test_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme attendu, les y_train_cat et y_test_cat sont maintenant des matrices avec 3 colonnes, une pour chaque classe considérée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilation du modèle\n",
    "Nous indiquons à Keras que notre modèle devra être optimisé en utilisant les éléments suivants :\n",
    "- la fonction d'optimisation d'Adam avec un taux d'aprentissage égal à 1e-3 ;\n",
    "- une fonction de perte d'entropie croisée ;\n",
    "- et en calculant la justesse à chaque itération. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définition des fonctions de rappel\n",
    "\n",
    "Nous utilisons la fonction de rappel de TensorBoard. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"log/fit/\"\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Entraînement du modèle\n",
    "Nous pouvons maintenant lancer l'entraînement du modèle, avec les paramètres suivants :\n",
    "- les données d'entraînement sont X_train et y_train_cat ;\n",
    "- les données de validation, utilisées pour l'affichage, sont X_test et y_test_cat, \n",
    "- nous demandons à la fonction d'optimisation de réaliser 100 époques ;\n",
    "- nous utilisons une taille de lot très réduite (8 exemples par lot), car notre jeu de données ne contient que peu d'exemples ;\n",
    "- et nous demandons à la fonction d'optimisation d'exécuter la fonction de rappel de TensorBoard à chaque itération, afin de sauvegarder les informations d'apprentissage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/12 [==============================] - 4s 56ms/step - loss: 2.4818 - accuracy: 0.3333 - val_loss: 1.9990 - val_accuracy: 0.3333\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.7463 - accuracy: 0.3444 - val_loss: 1.4512 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.2876 - accuracy: 0.6222 - val_loss: 1.0880 - val_accuracy: 0.6667\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.9956 - accuracy: 0.6667 - val_loss: 0.8971 - val_accuracy: 0.6333\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.8380 - accuracy: 0.7889 - val_loss: 0.8309 - val_accuracy: 0.6333\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.8250 - accuracy: 0.6667 - val_loss: 0.8134 - val_accuracy: 0.6667\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.7847 - accuracy: 0.6667 - val_loss: 0.7759 - val_accuracy: 0.6667\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.7525 - accuracy: 0.6778 - val_loss: 0.7467 - val_accuracy: 0.6667\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.7238 - accuracy: 0.7000 - val_loss: 0.7189 - val_accuracy: 0.6667\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.6967 - accuracy: 0.7000 - val_loss: 0.6920 - val_accuracy: 0.6500\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6721 - accuracy: 0.6889 - val_loss: 0.6666 - val_accuracy: 0.6667\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.6465 - accuracy: 0.7444 - val_loss: 0.6433 - val_accuracy: 0.7667\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6279 - accuracy: 0.7889 - val_loss: 0.6213 - val_accuracy: 0.6833\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.6079 - accuracy: 0.7556 - val_loss: 0.6042 - val_accuracy: 0.6833\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.5926 - accuracy: 0.6778 - val_loss: 0.5908 - val_accuracy: 0.6667\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5822 - accuracy: 0.6667 - val_loss: 0.5804 - val_accuracy: 0.6667\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5710 - accuracy: 0.6778 - val_loss: 0.5668 - val_accuracy: 0.6667\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5639 - accuracy: 0.7000 - val_loss: 0.5558 - val_accuracy: 0.7167\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5520 - accuracy: 0.6778 - val_loss: 0.5512 - val_accuracy: 0.6667\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5461 - accuracy: 0.7333 - val_loss: 0.5368 - val_accuracy: 0.7667\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5326 - accuracy: 0.8444 - val_loss: 0.5277 - val_accuracy: 0.7333\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5301 - accuracy: 0.6889 - val_loss: 0.5232 - val_accuracy: 0.6667\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5251 - accuracy: 0.7444 - val_loss: 0.5123 - val_accuracy: 0.7667\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5074 - accuracy: 0.7111 - val_loss: 0.5089 - val_accuracy: 0.6667\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5060 - accuracy: 0.6889 - val_loss: 0.4987 - val_accuracy: 0.7333\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4981 - accuracy: 0.8889 - val_loss: 0.4940 - val_accuracy: 0.9167\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4939 - accuracy: 0.9111 - val_loss: 0.4878 - val_accuracy: 0.9333\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.4884 - accuracy: 0.8778 - val_loss: 0.4809 - val_accuracy: 0.7667\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4813 - accuracy: 0.7778 - val_loss: 0.4762 - val_accuracy: 0.7167\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.4763 - accuracy: 0.6889 - val_loss: 0.4718 - val_accuracy: 0.7000\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.4712 - accuracy: 0.7000 - val_loss: 0.4653 - val_accuracy: 0.7833\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4686 - accuracy: 0.7000 - val_loss: 0.4610 - val_accuracy: 0.7667\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4631 - accuracy: 0.8778 - val_loss: 0.4605 - val_accuracy: 0.9500\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.4734 - accuracy: 0.8222 - val_loss: 0.4547 - val_accuracy: 0.9667\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.4557 - accuracy: 0.8111 - val_loss: 0.4504 - val_accuracy: 0.6833\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.4518 - accuracy: 0.7000 - val_loss: 0.4440 - val_accuracy: 0.7667\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.4490 - accuracy: 0.8778 - val_loss: 0.4385 - val_accuracy: 0.9833\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.4434 - accuracy: 0.8000 - val_loss: 0.4381 - val_accuracy: 0.7000\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.4417 - accuracy: 0.7333 - val_loss: 0.4294 - val_accuracy: 0.7833\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.4399 - accuracy: 0.9000 - val_loss: 0.4248 - val_accuracy: 0.9833\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.4318 - accuracy: 0.9000 - val_loss: 0.4228 - val_accuracy: 0.7833\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4275 - accuracy: 0.8000 - val_loss: 0.4172 - val_accuracy: 0.7833\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4221 - accuracy: 0.9111 - val_loss: 0.4124 - val_accuracy: 0.9833\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.4226 - accuracy: 0.8889 - val_loss: 0.4079 - val_accuracy: 0.9000\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.4147 - accuracy: 0.8667 - val_loss: 0.4035 - val_accuracy: 0.9167\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.4128 - accuracy: 0.9444 - val_loss: 0.4000 - val_accuracy: 0.9667\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.4069 - accuracy: 0.9444 - val_loss: 0.3964 - val_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4154 - accuracy: 0.8778 - val_loss: 0.3931 - val_accuracy: 0.8500\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.4082 - accuracy: 0.9000 - val_loss: 0.3892 - val_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.3991 - accuracy: 0.9444 - val_loss: 0.3855 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2406a409fa0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train_cat, validation_data=(X_test, y_test_cat), epochs=50, batch_size=8, callbacks=[tensorboard_callback])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
